{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import syllapy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted & saved article file for the bctech2011\n",
      "Successfully extracted & saved article file for the bctech2012\n",
      "Successfully extracted & saved article file for the bctech2013\n",
      "Successfully extracted & saved article file for the bctech2014\n",
      "Successfully extracted & saved article file for the bctech2015\n",
      "Successfully extracted & saved article file for the bctech2016\n",
      "Successfully extracted & saved article file for the bctech2017\n",
      "Successfully extracted & saved article file for the bctech2018\n",
      "Successfully extracted & saved article file for the bctech2019\n",
      "Successfully extracted & saved article file for the bctech2020\n",
      "Successfully extracted & saved article file for the bctech2021\n",
      "Successfully extracted & saved article file for the bctech2022\n",
      "Successfully extracted & saved article file for the bctech2023\n",
      "Successfully extracted & saved article file for the bctech2024\n",
      "Successfully extracted & saved article file for the bctech2025\n",
      "Successfully extracted & saved article file for the bctech2026\n",
      "Successfully extracted & saved article file for the bctech2027\n",
      "Successfully extracted & saved article file for the bctech2028\n",
      "Successfully extracted & saved article file for the bctech2029\n",
      "Successfully extracted & saved article file for the bctech2030\n",
      "Successfully extracted & saved article file for the bctech2031\n",
      "Successfully extracted & saved article file for the bctech2032\n",
      "Successfully extracted & saved article file for the bctech2033\n",
      "Successfully extracted & saved article file for the bctech2034\n",
      "Successfully extracted & saved article file for the bctech2035\n",
      "Successfully extracted & saved article file for the bctech2036\n",
      "Successfully extracted & saved article file for the bctech2037\n",
      "Successfully extracted & saved article file for the bctech2038\n",
      "Successfully extracted & saved article file for the bctech2039\n",
      "Successfully extracted & saved article file for the bctech2040\n",
      "Successfully extracted & saved article file for the bctech2041\n",
      "Successfully extracted & saved article file for the bctech2042\n",
      "Successfully extracted & saved article file for the bctech2043\n",
      "Successfully extracted & saved article file for the bctech2044\n",
      "Successfully extracted & saved article file for the bctech2045\n",
      "Successfully extracted & saved article file for the bctech2046\n",
      "Successfully extracted & saved article file for the bctech2047\n",
      "Successfully extracted & saved article file for the bctech2048\n",
      "Successfully extracted & saved article file for the bctech2049\n",
      "Successfully extracted & saved article file for the bctech2050\n",
      "Successfully extracted & saved article file for the bctech2051\n",
      "Successfully extracted & saved article file for the bctech2052\n",
      "Successfully extracted & saved article file for the bctech2053\n",
      "Successfully extracted & saved article file for the bctech2054\n",
      "Successfully extracted & saved article file for the bctech2055\n",
      "Successfully extracted & saved article file for the bctech2056\n",
      "Successfully extracted & saved article file for the bctech2057\n",
      "Successfully extracted & saved article file for the bctech2058\n",
      "Successfully extracted & saved article file for the bctech2059\n",
      "Successfully extracted & saved article file for the bctech2060\n",
      "Successfully extracted & saved article file for the bctech2061\n",
      "Successfully extracted & saved article file for the bctech2062\n",
      "Successfully extracted & saved article file for the bctech2063\n",
      "Successfully extracted & saved article file for the bctech2064\n",
      "Successfully extracted & saved article file for the bctech2065\n",
      "Successfully extracted & saved article file for the bctech2066\n",
      "Successfully extracted & saved article file for the bctech2067\n",
      "Successfully extracted & saved article file for the bctech2068\n",
      "Successfully extracted & saved article file for the bctech2069\n",
      "Successfully extracted & saved article file for the bctech2070\n",
      "Successfully extracted & saved article file for the bctech2071\n",
      "Successfully extracted & saved article file for the bctech2072\n",
      "Successfully extracted & saved article file for the bctech2073\n",
      "Successfully extracted & saved article file for the bctech2074\n",
      "Successfully extracted & saved article file for the bctech2075\n",
      "Successfully extracted & saved article file for the bctech2076\n",
      "Successfully extracted & saved article file for the bctech2077\n",
      "Successfully extracted & saved article file for the bctech2078\n",
      "Successfully extracted & saved article file for the bctech2079\n",
      "Successfully extracted & saved article file for the bctech2080\n",
      "Successfully extracted & saved article file for the bctech2081\n",
      "Successfully extracted & saved article file for the bctech2082\n",
      "Successfully extracted & saved article file for the bctech2083\n",
      "Successfully extracted & saved article file for the bctech2084\n",
      "Successfully extracted & saved article file for the bctech2085\n",
      "Successfully extracted & saved article file for the bctech2086\n",
      "Successfully extracted & saved article file for the bctech2087\n",
      "Successfully extracted & saved article file for the bctech2088\n",
      "Successfully extracted & saved article file for the bctech2089\n",
      "Successfully extracted & saved article file for the bctech2090\n",
      "Successfully extracted & saved article file for the bctech2091\n",
      "Successfully extracted & saved article file for the bctech2092\n",
      "Successfully extracted & saved article file for the bctech2093\n",
      "Successfully extracted & saved article file for the bctech2094\n",
      "Successfully extracted & saved article file for the bctech2095\n",
      "Successfully extracted & saved article file for the bctech2096\n",
      "Successfully extracted & saved article file for the bctech2097\n",
      "Successfully extracted & saved article file for the bctech2098\n",
      "Successfully extracted & saved article file for the bctech2099\n",
      "Successfully extracted & saved article file for the bctech2100\n",
      "Successfully extracted & saved article file for the bctech2101\n",
      "Successfully extracted & saved article file for the bctech2102\n",
      "Successfully extracted & saved article file for the bctech2103\n",
      "Successfully extracted & saved article file for the bctech2104\n",
      "Successfully extracted & saved article file for the bctech2105\n",
      "Successfully extracted & saved article file for the bctech2106\n",
      "Successfully extracted & saved article file for the bctech2107\n",
      "Successfully extracted & saved article file for the bctech2108\n",
      "Successfully extracted & saved article file for the bctech2109\n",
      "Successfully extracted & saved article file for the bctech2110\n",
      "Successfully extracted & saved article file for the bctech2111\n",
      "Successfully extracted & saved article file for the bctech2112\n",
      "Successfully extracted & saved article file for the bctech2113\n",
      "Successfully extracted & saved article file for the bctech2114\n",
      "Successfully extracted & saved article file for the bctech2115\n",
      "Successfully extracted & saved article file for the bctech2116\n",
      "Successfully extracted & saved article file for the bctech2117\n",
      "Successfully extracted & saved article file for the bctech2118\n",
      "Successfully extracted & saved article file for the bctech2119\n",
      "Successfully extracted & saved article file for the bctech2120\n",
      "Successfully extracted & saved article file for the bctech2121\n",
      "Successfully extracted & saved article file for the bctech2122\n",
      "Successfully extracted & saved article file for the bctech2123\n",
      "Successfully extracted & saved article file for the bctech2124\n",
      "Successfully extracted & saved article file for the bctech2125\n",
      "Successfully extracted & saved article file for the bctech2126\n",
      "Successfully extracted & saved article file for the bctech2127\n",
      "Successfully extracted & saved article file for the bctech2128\n",
      "Successfully extracted & saved article file for the bctech2129\n",
      "Successfully extracted & saved article file for the bctech2130\n",
      "Successfully extracted & saved article file for the bctech2131\n",
      "Successfully extracted & saved article file for the bctech2132\n",
      "Successfully extracted & saved article file for the bctech2133\n",
      "Successfully extracted & saved article file for the bctech2134\n",
      "Successfully extracted & saved article file for the bctech2135\n",
      "Successfully extracted & saved article file for the bctech2136\n",
      "Successfully extracted & saved article file for the bctech2137\n",
      "Successfully extracted & saved article file for the bctech2138\n",
      "Successfully extracted & saved article file for the bctech2139\n",
      "Successfully extracted & saved article file for the bctech2140\n",
      "Successfully extracted & saved article file for the bctech2141\n",
      "Successfully extracted & saved article file for the bctech2142\n",
      "Successfully extracted & saved article file for the bctech2143\n",
      "Successfully extracted & saved article file for the bctech2144\n",
      "Successfully extracted & saved article file for the bctech2145\n",
      "Successfully extracted & saved article file for the bctech2146\n",
      "Successfully extracted & saved article file for the bctech2147\n",
      "Successfully extracted & saved article file for the bctech2148\n",
      "Successfully extracted & saved article file for the bctech2149\n",
      "Successfully extracted & saved article file for the bctech2150\n",
      "Successfully extracted & saved article file for the bctech2151\n",
      "Successfully extracted & saved article file for the bctech2152\n",
      "Successfully extracted & saved article file for the bctech2153\n",
      "Successfully extracted & saved article file for the bctech2154\n",
      "Successfully extracted & saved article file for the bctech2155\n",
      "Successfully extracted & saved article file for the bctech2156\n",
      "Successfully extracted & saved article file for the bctech2157\n",
      "All articles processed!\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "df = pd.read_excel(\"input.xlsx\")\n",
    "\n",
    "# Directory to save the files into our machine.\n",
    "output_dir = \"extracted_articles\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def extract_article(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract the article title which is <h1> tag only\n",
    "    title = soup.find('h1').get_text(strip=True)\n",
    "    \n",
    "    # Extract the main article content from the specific div tag only\n",
    "    article_body = soup.find('div', class_='td-post-content tagdiv-type')\n",
    "    article_text = \"\"\n",
    "    \n",
    "    if article_body:\n",
    "        article_text = article_body.get_text(strip=True)\n",
    "    \n",
    "    return title, article_text\n",
    "\n",
    "# Loop through the DataFrame and process each URL\n",
    "for index, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    \n",
    "    try:\n",
    "        title, article_text = extract_article(url)\n",
    "        \n",
    "        # Save the article text to a text files.\n",
    "        with open(os.path.join(output_dir, f\"{url_id}.txt\"), \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(f\"{title}\\n\\n{article_text}\")\n",
    "        \n",
    "        print(f\"Successfully extracted & saved article file for the {url_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract article for {url_id}. Error: {str(e)}\")\n",
    "\n",
    "print(\"All articles processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentimental Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been updated for URL_ID bctech2011 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2012 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2013 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2014 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2015 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2016 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2017 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2018 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2019 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2020 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2021 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2022 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2023 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2024 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2025 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2026 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2027 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2028 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2029 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2030 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2031 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2032 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2033 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2034 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2035 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2036 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2037 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2038 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2039 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2040 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2041 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2042 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2043 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2044 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2045 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2046 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2047 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2048 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2049 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2050 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2051 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2052 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2053 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2054 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2055 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2056 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2057 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2058 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2059 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2060 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2061 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2062 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2063 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2064 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2065 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2066 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2067 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2068 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2069 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2070 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2071 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2072 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2073 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2074 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2075 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2076 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2077 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2078 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2079 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2080 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2081 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2082 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2083 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2084 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2085 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2086 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2087 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2088 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2089 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2090 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2091 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2092 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2093 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2094 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2095 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2096 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2097 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2098 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2099 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2100 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2101 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2102 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2103 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2104 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2105 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2106 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2107 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2108 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2109 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2110 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2111 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2112 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2113 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2114 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2115 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2116 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2117 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2118 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2119 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2120 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2121 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2122 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2123 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2124 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2125 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2126 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2127 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2128 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2129 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2130 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2131 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2132 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2133 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2134 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2135 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2136 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2137 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2138 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2139 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2140 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2141 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2142 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2143 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2144 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2145 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2146 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2147 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2148 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2149 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2150 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2151 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2152 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2153 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2154 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2155 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2156 and saved to Output Data Structure.xlsx\n",
      "Data has been updated for URL_ID bctech2157 and saved to Output Data Structure.xlsx\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import os\n",
    "\n",
    "# Load spaCy's English tokenizer\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Ensure stopwords are loaded\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def cleaned_word_count_spacy(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Tokenize the text into words\n",
    "    doc = tokenizer(text)\n",
    "    words = [token.text.lower().strip(string.punctuation) for token in doc if token.is_alpha]\n",
    "    # Remove stop words\n",
    "    cleaned_words = [word for word in words if word not in stop_words]\n",
    "    return len(cleaned_words)\n",
    "\n",
    "\n",
    "def gunning_fog_index(text):\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    # Remove any empty strings from the list\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = re.findall(r'\\w+', text)\n",
    "    \n",
    "    # Count the number of complex words (words with 3 or more syllables)\n",
    "    def count_syllables(word):\n",
    "        word = word.lower()\n",
    "        syllables = 0\n",
    "        vowels = \"aeiouy\"\n",
    "        if word[0] in vowels:\n",
    "            syllables += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                syllables += 1\n",
    "        if word.endswith(\"e\"):\n",
    "            syllables -= 1\n",
    "        if syllables == 0:\n",
    "            syllables += 1\n",
    "        return syllables\n",
    "    \n",
    "    complex_words = [word for word in words if count_syllables(word) >= 3]\n",
    "    \n",
    "    # average sentence length\n",
    "    average_sentence_length = len(words) / len(sentences)\n",
    "    \n",
    "    # Here, in textanalysis, that they have said that you do not have to multiply with 100 but in formula it should be.\n",
    "    complex_word_percentage = (len(complex_words) / len(words)) * 100 \n",
    "    \n",
    "    #the Gunning Fog Index\n",
    "    fog_index = 0.4 * (average_sentence_length + complex_word_percentage)\n",
    "    \n",
    "    return average_sentence_length,complex_word_percentage,fog_index,len(complex_words)\n",
    "\n",
    "def load_stopwords(stopwords_folder_path):\n",
    "    stopwords_set = set()\n",
    "    \n",
    "    # Iterate over all files in the stopwords folder\n",
    "    for filename in os.listdir(stopwords_folder_path):\n",
    "        file_path = os.path.join(stopwords_folder_path, filename)\n",
    "        \n",
    "        # Process all the stop words text files\n",
    "        if filename.endswith('.txt'):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='ISO-8859-1') as file:  # Try different encoding\n",
    "                    lines = file.read().splitlines()  # Read each line\n",
    "                    for line in lines:\n",
    "                        # Split words by delimiter '|' and normalize them\n",
    "                        words = [word.strip().lower() for word in line.split('|')]\n",
    "                        stopwords_set.update(words)\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Error decoding file {filename}, skipping.\")\n",
    "    \n",
    "    return stopwords_set\n",
    "\n",
    "def load_positive_stopwords(stopwords_folder_path):\n",
    "    stopwords_set = set()\n",
    "    \n",
    "    # Iterate over all files in the stopwords folder\n",
    "    for filename in os.listdir(stopwords_folder_path):\n",
    "        file_path = os.path.join(stopwords_folder_path, filename)\n",
    "        \n",
    "        # Process all the stop words text files\n",
    "        if \"positive-words\" in filename:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='ISO-8859-1') as file:  # Try different encoding\n",
    "                    lines = file.read().splitlines()  # Read each line\n",
    "                    for line in lines:\n",
    "                        # Split words by delimiter '|' and normalize them\n",
    "                        words = [word.strip().lower() for word in line.split('|')]\n",
    "                        stopwords_set.update(words)\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Error decoding file {filename}, skipping.\")\n",
    "    \n",
    "    return stopwords_set\n",
    "\n",
    "def load_negative_stopwords(stopwords_folder_path):\n",
    "    stopwords_set = set()\n",
    "    \n",
    "    # Iterate over all files in the stopwords folder\n",
    "    for filename in os.listdir(stopwords_folder_path):\n",
    "        file_path = os.path.join(stopwords_folder_path, filename)\n",
    "        \n",
    "        # Process all the stop words text files\n",
    "        if \"negative-words\" in filename:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='ISO-8859-1') as file:  # Try different encoding\n",
    "                    lines = file.read().splitlines()  # Read each line\n",
    "                    for line in lines:\n",
    "                        # Split words by delimiter '|' and normalize them\n",
    "                        words = [word.strip().lower() for word in line.split('|')]\n",
    "                        stopwords_set.update(words)\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Error decoding file {filename}, skipping.\")\n",
    "    \n",
    "    return stopwords_set\n",
    "\n",
    "def count_sentiments(unique_words, positive_words_set, negative_words_set):\n",
    "    \"\"\"Count positive and negative words in the unique words list.\"\"\"\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    \n",
    "    for word in unique_words:\n",
    "        if word in positive_words_set:\n",
    "            positive_count += 1\n",
    "        if word in negative_words_set:\n",
    "            negative_count -= 1\n",
    "    \n",
    "    return positive_count, negative_count\n",
    "\n",
    "def count_syllables(word):\n",
    "    return syllapy.count(word)\n",
    "\n",
    "def average_syllables_in_text(text):\n",
    "    # Split text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    \n",
    "    if not words:\n",
    "        return 0  # Avoid division by zero if text is empty or contains no words\n",
    "\n",
    "    # Count syllables per word\n",
    "    syllables_per_word = [count_syllables(word) for word in words]\n",
    "    \n",
    "    # Calculate average syllables\n",
    "    average_syllables = sum(syllables_per_word) / len(words)\n",
    "    \n",
    "    return average_syllables\n",
    "\n",
    "def count_total_personal_pronouns(text):\n",
    "    \"\"\"Counts the total number of personal pronouns in a given text.\n",
    "\n",
    "    Args:\n",
    "        text: The input text.\n",
    "\n",
    "    Returns:\n",
    "        The total count of personal pronouns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define personal pronouns to count, considering both uppercase and lowercase\n",
    "    pronouns = [\"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\",\"me\", \"you\", \"him\", \"her\", \"it\", \"us\", \"them\",\"my\", \"your\", \"his\", \"her\", \"its\", \"our\", \"their\",\"myself\", \"yourself\", \"himself\", \"herself\", \"itself\", \"ourselves\",\"themselves\",\"this\", \"that\", \"these\", \"those\"]\n",
    "    # Create a regex pattern to match personal pronouns, avoiding \"US\" as a country\n",
    "    pattern = r'\\b(?:' + '|'.join(pronouns) + r')\\b(?!\\s*[^ ]*\\bUS\\b)'\n",
    "\n",
    "    # Find all matches using regex, case-insensitive\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    # Return the total count of personal pronouns\n",
    "    return len(matches)\n",
    "\n",
    "def average_word_length(text):\n",
    "    # Use regex to find all words in the text\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    \n",
    "    # Calculate the total number of characters in all words\n",
    "    total_characters = sum(len(word) for word in words)\n",
    "    \n",
    "    # Calculate the total number of words\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # Calculate the average word length\n",
    "    avg_length = total_characters / total_words if total_words > 0 else 0\n",
    "    \n",
    "    return avg_length\n",
    "\n",
    "def store_Excel(url_id,var1,var2,var3,var4,var5,var6,var7,var8,var9,var10,var11,var12,var13):\n",
    "    excel_file_path = 'Output Data Structure.xlsx'\n",
    "\n",
    "    # Read the existing Excel file into a DataFrame\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "\n",
    "\n",
    "    new_data = {\n",
    "        'URL_ID': url_id,  # The URL_ID to find\n",
    "        'Variables': [var1,var2,var3,var4,var5,var6,var7,var8,var9,var10,var11,var12,var13]\n",
    "    }\n",
    "\n",
    "    # Extract URL_ID and new variables\n",
    "    url_id_to_find = new_data['URL_ID']\n",
    "    new_variables = new_data['Variables']\n",
    "    columns_to_update = df.columns[2:]  # All columns from the 3rd one onward\n",
    "\n",
    "    # Ensure the new variables list is the same length as the columns to update\n",
    "    assert len(new_variables) == len(columns_to_update), \"The number of variables does not match the number of columns to update.\"\n",
    "\n",
    "    #  Update the DataFrame\n",
    "    df.loc[df['URL_ID'] == url_id_to_find, columns_to_update] = new_variables\n",
    "\n",
    "    # Save the updated DataFrame back to the Excel file\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Data has been updated for URL_ID {url_id_to_find} and saved to {excel_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_unique_words_from_files(folder_path,stopwords_set,positive_words_set,negative_words_set):\n",
    "\n",
    "    # Iterate over all files in the file of the text file\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        word_list = [] \n",
    "        file_content = ''\n",
    "        # Process only text files\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                file_content = content\n",
    "                # Find all words using regex\n",
    "                words = re.findall(r'\\b\\w+\\b', content.lower())  # Convert to lower case to normalize\n",
    "                # Add words to the list if they are not already present\n",
    "                for word in words:\n",
    "                    if word not in stopwords_set:\n",
    "                        word_list.append(word)\n",
    "\n",
    "        #1  Extracting Derived variables\n",
    "        total_counts = len(word_list)\n",
    "\n",
    "        positive_score, negative_score = count_sentiments(word_list, positive_words_set, negative_words_set)\n",
    "        negative_score = negative_score * -1\n",
    "        \n",
    "        Polarity_Score = (positive_score-negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "\n",
    "        Subjectivity_Score = (positive_score+negative_score)/ ((total_counts) + 0.000001)\n",
    "        \n",
    "        #print(positive_score,negative_score,Polarity_Score,Subjectivity_Score)\n",
    "\n",
    "        #2\tAnalysis of Readability (Gunning Fox Index)\n",
    "        Average_Sentence_length, Percentage_complex_words,Fog_index,complex_count = gunning_fog_index(file_content)\n",
    "        #print(Average_Sentence_length,Percentage_complex_words,Fog_index)\n",
    "        ''' A Fog Index score of 7-8 is considered fairly easy to read, suitable for most people.\n",
    "            A score of 12 indicates the reading level of a high school senior.\n",
    "            A score of 16 or above suggests the text is very difficult to read, requiring advanced education to understand. '''\n",
    "\n",
    "        #3\tAverage Number of Words Per Sentence\n",
    "        #print(Average_Sentence_length)\n",
    "\n",
    "        #4\tComplex Word Count\n",
    "        #print(complex_count)\n",
    "\n",
    "        #5\tWord Count\n",
    "        spacy_word_count = cleaned_word_count_spacy(file_content)\n",
    "        #print(spacy_word_count)\n",
    "        #6 Syllabe per word\n",
    "        count_syllables=average_syllables_in_text(file_content)\n",
    "        #print(count_syllables)\n",
    "\n",
    "        #8 Personal Pronoun\n",
    "        count_PP = count_total_personal_pronouns(file_content)\n",
    "        #print(count_PP)\n",
    "\n",
    "        #9 average length\n",
    "        avg_length = average_word_length(file_content)\n",
    "\n",
    "\n",
    "        url_id = filename.replace('.txt', '')\n",
    "\n",
    "        store_Excel(url_id,positive_score, negative_score,Polarity_Score,Subjectivity_Score,Average_Sentence_length,Percentage_complex_words,Fog_index,Average_Sentence_length,complex_count,spacy_word_count,count_syllables,count_PP,avg_length)\n",
    "\n",
    "folder_path = 'extracted_articles' \n",
    "stopwords_folder_path = 'StopWords'  \n",
    "positive_file_path = 'MasterDictionary'\n",
    "negative_file_path = 'MasterDictionary'\n",
    "\n",
    "stopwords_set = load_stopwords(stopwords_folder_path)\n",
    "positive_words_set = load_positive_stopwords(positive_file_path)\n",
    "negative_words_set = load_negative_stopwords(negative_file_path)\n",
    "\n",
    "\n",
    "extract_unique_words_from_files(folder_path,stopwords_set,positive_words_set,negative_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
